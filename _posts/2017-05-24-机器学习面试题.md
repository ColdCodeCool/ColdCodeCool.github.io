---
layout: post
title: "机器学习面试题及解答"
date: 2017-05-24 13:54:06
categories: Interview
---
## 算法及原理类

Q1:偏差（bias）和方差之间的trade-off是什么？

- 偏差是由学习算法中错误的或过于简单的假设导致的。高偏差能导致算法忽略特征与目标输出的相关性，从而导致欠拟合（underfitting）。
- 方差是由学习算法中过于复杂的假设或模型导致的。这将导致你的算法对训练集中高度变化的数据过于敏感，从而导致模型过拟合（overfitting）。这样一来你的模型将携带太多的噪声导致模型在测试集上失效。

偏差-方差分解（bias-variance decomposition）通过将基于数据集中噪声的偏差，方差和由于噪声引起的不可避免的误差加在一起，从而分解了学习误差。本质上，如果你使模型更加复杂或增加更多变量，偏差会减小而方差会增大，因此我们需要在偏差方差上做权衡。

Q2:监督学习和无监督学习之间的区别是什么？

监督学习训练时要求带标签的数据，比如，为了进行分类（一种监督学习任务），你需要首先对数据打标签，从而你的训练模型才能对数据分类到其对应的标签组。

Q3:K最近邻与k-means聚类有什么区别？

k最近邻是一个监督学习算法，k-means是无监督学习算法。为使k最近邻算法工作，你需要带标签的数据从而将一个未被打标签的点分类。而k-means聚类仅仅需要一个未打标签的点集合以及一个门限：算法将不带标签的数据作为输入，并逐渐通过计算不同点之间的距离均值学习如何将它们聚类。

Q4:说明ROC曲线如何工作的。

ROC曲线是一个基于不同门限的真正率和假正率对比的图形化表示。它经常被用来作为权衡模型敏感性（真正率）与模型触发虚警概率（假正率）的代理。

Q5:定义精确率（precision）和召回率（recall)

召回率也就是真正率：即模型正确预测的正样本数量占应该被预测到的正样本数量的比例。精确率则是模型正确预测的正样本占实际被预测的正样本比例。举个例子，假如某个班级有男生80人，女生20人，共计100人。目标是找出所有女生，现在某人挑选出50个人，其中20个人是女生，另外还错误地把30个男生也当作女生挑选出来了。作为评估者的你来评价一下他的工作。

首先我们可以计算准确率（accuracy），其定义是：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。也就是损失函数是0-1损失时测试数据集上的准确率。结合实例，挑选者判定正确了20女+50男，而总人数是100，那么准确率是70%。

由准确率，我们的确可以在一些场合，从某种意义上得出一个分类器是否有效，但它并不是总能有效地评价一个分类器的性能。举例来说，google抓取了100个目标页面，而它索引中共有10，000，000个页面，随机抽一个页面，分类它是否目标页面？如果以accuracy作为指标来判定分类器性能，那我们可以选定一个无脑的分类器：它总是将抽取的页面判断为非目标页面，这样我们仍能得到9，999，900/10，000，000=99.999%的accuracy，显然这不合理。

那么我们需要引入precision，recall和f1-measure的概念，而在此之前要先定义TP，FP，FN，TN四种分类情况。在我们的例子中，TP=20，FP=30，FN=0，TN=50.

精确率公式是$P=\frac{TP}{TP+FP}$.
召回率$R=\frac{TP}{TP+FN}$.
F1=$\frac{2PR}{P+R}$，也即

$$
\frac{2}{F_1}=\frac{1}{P}+\frac{1}{R}
$$

Q6:什么是贝叶斯定理？

贝叶斯定理基于先验知识给出了一个事件的后验概率。

数学上来说，它表示了一个条件样本的真正率比上种群假正率与条件样本真正率之和。比如，你在流感测试后有60%的概率真的患流感，在所有患流感的人群中，有50%的概率测试会出错，并且整个人群中只有5%的概率患流感。那么你在一次流感测试中是否有60%的概率患流感。

答案是否定的。实际上你有

$$
\frac{0.6*0.05}{0.6*0.05+0.5*0.95}=0.0594
$$

的概率患流感。

Q7:为什么叫朴素贝叶斯？

朴素贝叶斯假设特征之间相互独立，互不影响。拿分类问题举例，对于样本$\textbf{x}$(假设是一个n维的向量)，我们要求$p(y\|\textbf{x})$，来估计所属类别。

根据贝叶斯公式，可以得到：

$$
p(y|\textbf{x})=p(\textbf{x}|y)p(y)/p(\textbf{x})
$$

右边的这个$p(\textbf{x}\|y)$是我我们希望通过训练样本求得的。如果是普通的贝叶斯，那么这个$p(\textbf{x}\|y)$会很大，与n的大小呈指数级增长；

如果是朴素贝叶斯，那么

$$
p(\textbf{x}|y)=p(x_1,x_2,\ldots|y)=p(x_1|y)*p(x_2|y)*\ldots
$$

这样以来，就可以把hypothesis的空间减小到与n的大小是线性关系了。

Q8:解释L1和L2正则化的区别。

它们最主要的区别是l1正则能生成稀疏模型，而l2正则不能。因此l1正则通常被用来在稀疏的特征空间中提取特征。

Q9:解释什么是第一类和第二类错误

第一类错误是假正，第二类错误是假负。假正的意思是声称事情发生了但实际上没有发生，假负的意思是声称事情没有发生，但实际发生了。

Q10:解释什么是傅立叶变换

傅立叶变换是一种通用的将任意函数分解成一组对称函数组合的方法。傅立叶变换将信号从时域变换到频域，在声音信号和其他时间序列信号比如传感器信号处理中是一种通用的提取特征的方法。

Q11:解释概率和似然的区别

$P(x\|\theta)$有两种解释：

- 作为以x为变量的函数，$\theta$已知。这样一来，$P(x\|\theta)$则被称作以$\theta$为模型参数，事件x发生的概率。
- 作为以$\theta$为变量的函数，事件x已知（被观察到的）。比如，要找到一个$\hat{\theta}$作为$\theta$的估计最大化$P(x\|\theta)$，那么$P(x\|\hat{\theta})$则被称为给定事件x的$\theta$的最大似然，通常记为$\mathcal{L}(\theta\|x)$。所以似然是对于给定事件x在不同$\theta$赋值情况下的概率$P(x\|\theta)$的简称。

Q12:解释什么是深度学习以及其与其他机器学习算法的区别

深度学习是机器学习的子集，并且着重于神经网络：怎样使用反向传播和其他来自于神经科学的准则来更精确地建模大规模无标签或半结构化的数据。

Q13:生成式模型与判别式模型的区别

- 生成式模型求解数据是如何产生从而归类一个信号（得到数据与类别的联合概率分布），它提出的问题是：基于我的生成假设，哪一类信号最可能被产生。（往往研究的是成对的数据）

- 判别式模型不关心数据如何产生的，仅仅研究如何分类信号。（求的是给定数据的条件概率）

Q14:对于时间序列信号你应采用什么交叉验证法

我们必须注意时间序列不是随机分布的数据，它是按时间顺序固有排序的，因此不能使用标准的k-fold交叉验证。

我们可以进行前向链式训练：

- fold 1:training[1],test[2]
- fold 2:training[1 2],test[3]
- fold 3:training[1 2 3],test[4]
- fold 4:training[1 2 3 4], test[5]
- fold 5:training[1 2 3 4 5], test[6]

Q15:决策树是如何剪枝的

剪枝发生在决策树的某些分支预测能力比较弱的情况下，剪掉这些分支将带来模型复杂度的降低或提升模型预测能力。剪枝可以自底向上也可以自顶向下，主要是通过比较子树的损失函数，损失大的子树被剪掉。利用损失函数最小原则进行剪枝就是用正则化的极大似然估计进行模型选择。

Q16:模型准确率和模型性能哪个更重要？

准确率只是模型性能的一部分性质，不能完整地刻画模型的性能，甚至还会产生误导。比如，在一个超大数据集里检测1的个数，如果数据集大部分都是0，那么仅仅对所有样本做出为0的预测，模型就可以达到非常高的准确率。

Q17:什么是F1分数

F1分数是一个模型性能的评价值。它是模型精确率和召回率的调和平均，往往适用于真假率不显著的分类任务中。

Q18:如何处理不平衡数据集

一个不平衡的数据集，比如对一个分类测试，90%的数据是一个类别。这样即使模型对另一个类型毫无分辨能力，也能获得90%的准确率。这时我们需要进行一些操作：

- 收集更多的数据来平衡数据集
- 重新采样数据集
- 尝试不同的算法

Q19:什么时候用分类，什么时候用回归

分类适用于输出为离散值，回归适用于输出为连续值。

Q20:举一个适用于集成学习的例子

集成学习用一个组合式的学习算法来优化预测性能，并渐小过拟合。常见的bagging，boosting。

Q21:如何确定模型没有过拟合

过拟合奖训练集的噪声带入了测试集，导致泛化性能降低

- 保持模型简单：用尽量少的变量和参数移除训练集中噪声的影响来减小方差
- 利用交叉验证，比如k-fold交叉验证
- 用正则化技术来惩罚导致过拟合的参数

Q22:如何验证模型有效

首先将数据集分为训练集和测试集，还可以将数据集进一步分为训练集，验证集，测试集。然后选择一种模型性能指标，常见比如F1-score，准确率（accuracy），confusion matrix等。在这里重要的是要表明你知道模型评估的细节，并且能够根据具体情况选择正确的性能指标。

Q23:什么是核技巧？

核技巧包含可以应用在高维空间的核函数，而无需明确计算该维度内的点的坐标：相反，核函数计算特征空间中所有数据对的内积。由于很多算法都可以表示成内积的形式，所以使用核技巧可以使我们用低维数据在高维空间应用算法。


## 编程方面

Q24:如何处理缺失值和污染数据

如果你发现数据集中有缺失值或污染数据，你要么丢弃这些行或列，要么将它们替换为其他值。

在Pandas中，有两个有用的函数isnull()和dropna()可以帮助你找到缺失或污染的数据列并丢弃它们。如果你想在这些数据位置补上占位值（placeholder）比如0，那么可以使用fillna()。

Q25:你是否具有大数据处理工具spark等的经验

如实回答，如果没有经验，那就尽快使自己熟悉。

Q26:选择一个算法，用并行计算的方式写出它的伪代码

学习使用[Peril-L](http://www.eng.utah.edu/~cs4960-01/lecture4.pdf)这个伪代码框架和[web sequence diagrams](https://www.websequencediagrams.com/)，来训练并行化思想。

Q27:链表和数组的区别是什么

数组是一个有序（这里有序是指下标）的对象集合。链表是一个带指针的对象序列，所以处理的时候需要序列化地处理。数组假设其中的每一个对象都有同样的大小，而链表不是。如果需要增大尺寸的话，数组需要预先定义或重定义大小，而链表不需要。打乱链表只需要改变指针的指向，而打乱数组更加复杂并且需要更多内存。

Q28:描述一下哈希表

哈希表是一种用于产生关联数组的数据结构。秘钥通过使用散列函数映射到某些值，它们通常用于诸如数据库索引等任务。

Q29:你都适用哪些可视化库

matplotlib和seaborn

## 工业界方面

Q30:对本公司用户如何设计一个推荐系统

你需要深入了解该公司及其行业，特别是公司的收入来源，以及公司在其行业背景下所持有的用户类型。





