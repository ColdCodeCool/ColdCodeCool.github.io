---
layout: post
title: "机器学习面试题及解答"
date: 2017-05-24 13:54:06
categories: Interview
---
## 算法及原理类

$\color[red]{Q1:偏差（bias）和方差之间的trade-off是什么？}$

- 偏差是由学习算法中错误的或过于简单的假设导致的。高偏差能导致算法忽略特征与目标输出的相关性，从而导致欠拟合（underfitting）。
- 方差是由学习算法中过于复杂的假设或模型导致的。这将导致你的算法对训练集中高度变化的数据过于敏感，从而导致模型过拟合（overfitting）。这样一来你的模型将携带太多的噪声导致模型在测试集上失效。

偏差-方差分解（bias-variance decomposition）通过将基于数据集中噪声的偏差，方差和由于噪声引起的不可避免的误差加在一起，从而分解了学习误差。本质上，如果你使模型更加复杂或增加更多变量，偏差会减小而方差会增大，因此我们需要在偏差方差上做权衡。

Q2:监督学习和无监督学习之间的区别是什么？

监督学习训练时要求带标签的数据，比如，为了进行分类（一种监督学习任务），你需要首先对数据打标签，从而你的训练模型才能对数据分类到其对应的标签组。

Q3:K最近邻与k-means聚类有什么区别？

k最近邻是一个监督学习算法，k-means是无监督学习算法。为使k最近邻算法工作，你需要带标签的数据从而将一个未被打标签的点分类。而k-means聚类仅仅需要一个未打标签的点集合以及一个门限：算法将不带标签的数据作为输入，并逐渐通过计算不同点之间的距离均值学习如何将它们聚类。

Q4:说明ROC曲线如何工作的。

ROC曲线是一个基于不同门限的真正率和假正率对比的图形化表示。它经常被用来作为权衡模型敏感性（真正率）与模型触发虚警概率（假正率）的代理。

Q5:定义精确率（precision）和召回率（recall)

召回率也就是真正率：即模型正确预测的正样本数量占应该被预测到的正样本数量的比例。精确率则是模型正确预测的正样本占实际被预测的正样本比例。举个例子，假如某个班级有男生80人，女生20人，共计100人。目标是找出所有女生，现在某人挑选出50个人，其中20个人是女生，另外还错误地把30个男生也当作女生挑选出来了。作为评估者的你来评价一下他的工作。

首先我们可以计算准确率（accuracy），其定义是：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。也就是损失函数是0-1损失时测试数据集上的准确率。结合实例，挑选者判定正确了20女+50男，而总人数是100，那么准确率是70%。

由准确率，我们的确可以在一些场合，从某种意义上得出一个分类器是否有效，但它并不是总能有效地评价一个分类器的性能。举例来说，google抓取了100个目标页面，而它索引中共有10，000，000个页面，随机抽一个页面，分类它是否目标页面？如果以accuracy作为指标来判定分类器性能，那我们可以选定一个无脑的分类器：它总是将抽取的页面判断为非目标页面，这样我们仍能得到9，999，900/10，000，000=99.999%的accuracy，显然这不合理。

那么我们需要引入precision，recall和f1-measure的概念，而在此之前要先定义TP，FP，FN，TN四种分类情况。在我们的例子中，TP=20，FP=30，FN=0，TN=50.

精确率公式是$P=\frac{TP}{TP+FP}$.
召回率$R=\frac{TP}{TP+FN}$.
F1=$\frac{2PR}{P+R}$，也即

$$
\frac{2}{F_1}=\frac{1}{P}+\frac{1}{R}
$$

Q6:什么是贝叶斯定理？

贝叶斯定理基于先验知识给出了一个事件的后验概率。

数学上来说，它表示了一个条件样本的真正率比上种群假正率与条件样本真正率之和。比如，你在流感测试后有60%的概率真的患流感，在所有患流感的人群中，有50%的概率测试会出错，并且整个人群中只有5%的概率患流感。那么你在一次流感测试中是否有60%的概率患流感。

答案是否定的。实际上你有

$$
\frac{0.6*0.05}{0.6*0.05+0.5*0.95}=0.0594
$$

的概率患流感。

Q7:为什么叫朴素贝叶斯？

朴素贝叶斯假设特征之间相互独立，互不影响。拿分类问题举例，对于样本$\textbf{x}$(假设是一个n维的向量)，我们要求$p(y\|\textbf{x})$，来估计所属类别。

根据贝叶斯公式，可以得到：

$$
p(y|\textbf{x})=p(\textbf{x}|y)p(y)/p(\textbf{x})
$$

右边的这个$p(\textbf{x}\|y)$是我我们希望通过训练样本求得的。如果是普通的贝叶斯，那么这个$p(\textbf{x}\|y)$会很大，与n的大小呈指数级增长；

如果是朴素贝叶斯，那么

$$
p(\textbf{x}|y)=p(x_1,x_2,\ldots|y)=p(x_1|y)*p(x_2|y)*\ldots
$$

这样以来，就可以把hypothesis的空间减小到与n的大小是线性关系了。

Q8:解释L1和L2正则化的区别。

它们最主要的区别是l1正则能生成稀疏模型，而l2正则不能。因此l1正则通常被用来在稀疏的特征空间中提取特征。

Q9:解释什么是第一类和第二类错误

第一类错误是假正，第二类错误是假负。假正的意思是声称事情发生了但实际上没有发生，假负的意思是声称事情没有发生，但实际发生了。

Q10:解释什么是傅立叶变换

傅立叶变换是一种通用的将任意函数分解成一组对称函数组合的方法。傅立叶变换将信号从时域变换到频域，在声音信号和其他时间序列信号比如传感器信号处理中是一种通用的提取特征的方法。

Q11:解释概率和似然的区别

$P(x\|\theta)$有两种解释：

- 作为以x为变量的函数，$\theta$已知。这样一来，$P(x\|\theta)$则被称作以$\theta$为模型参数，事件x发生的概率。
- 作为以$\theta$为变量的函数，事件x已知（被观察到的）。比如，要找到一个$\hat{\theta}$作为$\theta$的估计最大化$P(x\|\theta)$，那么$P(x\|\hat{\theta})$则被称为给定事件x的$\theta$的最大似然，通常记为$\mathcal{L}(\theta\|x)$。所以似然是对于给定事件x在不同$\theta$赋值情况下的概率$P(x\|\theta)$的简称。

Q12:解释什么是深度学习以及其与其他机器学习算法的区别

深度学习是机器学习的子集，并且着重于神经网络：怎样使用反向传播和其他来自于神经科学的准则来更精确地建模大规模无标签或半结构化的数据。

Q13:生成式模型与判别式模型的区别

- 生成式模型求解数据是如何产生从而归类一个信号（得到数据与类别的联合概率分布），它提出的问题是：基于我的生成假设，哪一类信号最可能被产生。（往往研究的是成对的数据）

- 判别式模型不关心数据如何产生的，仅仅研究如何分类信号。（求的是给定数据的条件概率）

Q14:对于时间序列信号你应采用什么交叉验证法

我们必须注意时间序列不是随机分布的数据，它是按时间顺序固有排序的，因此不能使用标准的k-fold交叉验证。

我们可以进行前向链式训练：

- fold 1:training[1],test[2]
- fold 2:training[1 2],test[3]
- fold 3:training[1 2 3],test[4]
- fold 4:training[1 2 3 4], test[5]
- fold 5:training[1 2 3 4 5], test[6]

Q15:决策树是如何剪枝的

剪枝发生在决策树的某些分支预测能力比较弱的情况下，剪掉这些分支将带来模型复杂度的降低或提升模型预测能力。剪枝可以自底向上也可以自顶向下，主要是通过比较子树的损失函数，损失大的子树被剪掉。利用损失函数最小原则进行剪枝就是用正则化的极大似然估计进行模型选择。

Q16:模型准确率和模型性能哪个更重要？

准确率只是模型性能的一部分性质，不能完整地刻画模型的性能，甚至还会产生误导。比如，在一个超大数据集里检测1的个数，如果数据集大部分都是0，那么仅仅对所有样本做出为0的预测，模型就可以达到非常高的准确率。

Q17:什么是F1分数

F1分数是一个模型性能的评价值。它是模型精确率和召回率的调和平均，往往适用于真假率不显著的分类任务中。

Q18:如何处理不平衡数据集

一个不平衡的数据集，比如对一个分类测试，90%的数据是一个类别。这样即使模型对另一个类型毫无分辨能力，也能获得90%的准确率。这时我们需要进行一些操作：

- 收集更多的数据来平衡数据集
- 重新采样数据集
- 尝试不同的算法

Q19:什么时候用分类，什么时候用回归

分类适用于输出为离散值，回归适用于输出为连续值。

Q20:举一个适用于集成学习的例子

集成学习用一个组合式的学习算法来优化预测性能，并渐小过拟合。常见的bagging，boosting。

Q21:如何确定模型没有过拟合

过拟合奖训练集的噪声带入了测试集，导致泛化性能降低

- 保持模型简单：用尽量少的变量和参数移除训练集中噪声的影响来减小方差
- 利用交叉验证，比如k-fold交叉验证
- 用正则化技术来惩罚导致过拟合的参数

Q22:如何验证模型有效

首先将数据集分为训练集和测试集，还可以将数据集进一步分为训练集，验证集，测试集。然后选择一种模型性能指标，常见比如F1-score，准确率（accuracy），confusion matrix等。在这里重要的是要表明你知道模型评估的细节，并且能够根据具体情况选择正确的性能指标。

Q23:什么是核技巧？

核技巧包含可以应用在高维空间的核函数，而无需明确计算该维度内的点的坐标：相反，核函数计算特征空间中所有数据对的内积。由于很多算法都可以表示成内积的形式，所以使用核技巧可以使我们用低维数据在高维空间应用算法。


## 编程方面

Q24:如何处理缺失值和污染数据

如果你发现数据集中有缺失值或污染数据，你要么丢弃这些行或列，要么将它们替换为其他值。

在Pandas中，有两个有用的函数isnull()和dropna()可以帮助你找到缺失或污染的数据列并丢弃它们。如果你想在这些数据位置补上占位值（placeholder）比如0，那么可以使用fillna()。

Q25:你是否具有大数据处理工具spark等的经验

如实回答，如果没有经验，那就尽快使自己熟悉。

Q26:选择一个算法，用并行计算的方式写出它的伪代码

学习使用[Peril-L](http://www.eng.utah.edu/~cs4960-01/lecture4.pdf)这个伪代码框架和[web sequence diagrams](https://www.websequencediagrams.com/)，来训练并行化思想。

Q27:链表和数组的区别是什么

数组是一个有序（这里有序是指下标）的对象集合。链表是一个带指针的对象序列，所以处理的时候需要序列化地处理。数组假设其中的每一个对象都有同样的大小，而链表不是。如果需要增大尺寸的话，数组需要预先定义或重定义大小，而链表不需要。打乱链表只需要改变指针的指向，而打乱数组更加复杂并且需要更多内存。

Q28:描述一下哈希表

哈希表是一种用于产生关联数组的数据结构。秘钥通过使用散列函数映射到某些值，它们通常用于诸如数据库索引等任务。

Q29:你都适用哪些可视化库

matplotlib和seaborn

## 工业界方面

Q30:对本公司用户如何设计一个推荐系统

你需要深入了解该公司及其行业，特别是公司的收入来源，以及公司在其行业背景下所持有的用户类型。

Q31:给你一个1000列和100万行的数据集，用来做分类任务。你的经理要求你降低数据的维度，从而降低模型的计算量。同时你的机器有内存限制，你将怎么做？

- 首先我们关闭其他的应用程序包括浏览器，以降低无关的内存占用。
- 其次我们可以随机抽样数据集，也就是说我们可以重新构造一个较小的数据集。
- 降维，我们分离数值和类别变量，并且移除互相关联的变量。对数值变量，我们使用互相关。对类别变量，我们使用卡方检验，例如皮尔森卡方检验。
- 同时，可以使用PCA并且选取对数据集方差贡献最大的成分。
- 使用在线算法。
- 建立线性模型并使用随机梯度下降。

Q32:在PCA中rotation(orthogonal)是必要的吗？如果是，那么不旋转会怎样？

是必要的，因为正交可以使成分的方差之间的差异最大化。这样使得不同成分之间区分开，我们从中选择更少的组分来表征数据集。如果不正交，那么我们将不得不选择更多的成分。

Q33:如果给定一个数据集，已知数据集有缺失值并且分布在以均值为中心方差为1的区域内，那么将有多少比例的数据不受影响？

若数据服从正态分布，那么以均值为中心方差为1的区域内有大约68%的数据落在该区域，那么就有32%的数据不受影响。

Q34:在朴素贝叶斯的语境下解释什么是先验概率，似然（likelihood）和边际似然

先验概率就是在数据集中各类别的所占的比例。它是在不给其他信息的情况下，所能猜对一个数据的类别的最大概率。

似然就是在给定其他变量时分类一个给定观察的概率，比如在垃圾邮件分类时，单词“free”在上一封垃圾邮件中使用的概率是似然，而边际似然是“free”在任何一封邮件中使用的概率。

Q35:给你一个时间序列数据集，你一开始使用了决策树算法，后来你使用了时间序列回归模型，你得到了比决策树算法更高的准确率。这是可能的吗？

可能。时间序列是线性的，但是决策树算法在处理非线性关系时能获得最好的性能。所以，决策树算法不能提供鲁棒的预测是因为它不能像回归模型那样很好地映射线性关系。

Q36:你现在了解到你的模型具有低偏差和高误差。你应该选择哪个算法来解决，为什么？

当模型的预测值接近实际值时，产生低偏差。换句话说，该模型变得足够灵活以模拟训练数据分布。虽然这听起来效果不错，但是灵活的模型没有泛化能力。这意味着，当这个模型在一个新数据集上运行时，它会产生令人失望的结果。

在这种情况下，我们可以使用bagging方法，比如（随机森林）来解决高方差问题。bagging方法将数据集划分为通过重复随机抽样形成的子集。然后，这些样本用于一组被选择的算法来训练生成一组模型。之后，使用voting（分类）或averaging（回归）来组合模型预测。

同时，克服高偏差，我们也可以：

- 使用正则化技术，惩罚较大的模型系数，简化模型，降低过拟合。
- 依据变量重要性表使用top n特征。

Q37:当你使用了几个小时来建立一个高准确率模型，选择了boosting算法但并不能达到预期。为什么？

我们知道，集成学习器基于将若干弱学习器结合成强学习器的思想，但是这一方法奏效的前提是这些被组合的模型是不相关的。

Q38:kNN和kmeans有什么区别

首先，knn是监督学习，kmeans是无监督学习。

kmeans把数据集分成几个簇，每个簇内数据性质相同。knn算法基于k个相邻邻居尝试分类一个未打标签数据为其中之一。

Q39:检测了模型之后，你的经理告诉你你的回归模型存在multicollinearity，你如何检验他说的是否正确？并且在不丢失信息的情况下，能否得到更好的模型。

检查multicollinearity，我们可以使用互相关矩阵来移除相关度大于75%的变量。同时，我们也可以计算VIF来（variance inflation factor）来检查multicollinearity。VIF<=4则表示没有，VIF>=10则预示强烈的multicollinearity. 并且，我们还可使用tolerance。

但是移除相关变量会导致潜在丢失信息，因此我们可以使用惩罚回归模型，比如ridge或lasso。

我们也可以在相关的变量中加入一点噪声，但是加噪声会导致预测准确率下降。

Q40:什么时候ridge回归要优于lasso回归

当面临少数变量的中等或大型数据集时，用lasso回归，当变量很多并且数据集为小规模或中等规模时，用ridge回归。

从概念上说，lasso回归（L1正则）同时进行了变量选择和参数收缩，而ridge回归只进行了参数收缩从而保留了所有模型系数。

Q41:在处理一个数据集时，如何选择关键变量（feature engineering）

- 首先移除互相关的变量
- 使用线性回归，根据p值选择变量
- 使用forward selection，backward selection，stepwise selection
- 使用random forest，Xgboost，并刻画变量重要性表
- 使用lasso回归
- 对数据集可用的features，评估其信息增益，并依此选择top n features

Q42:解释相关和协方差的区别

相关（correlation）是标准化的协方差

Q43：是否有可能获取连续变量和离散分类变量的相关性，如果可以，如何进行

是，我们可以使用ANCOVA（analysis of covariance）。

Q44：同样是基于树的算法，随机森林（random forest）与梯度提升算法（gradient boosting algorithm）有什么区别

对于bagging算法，用随机化采样（有放回）将一个数据集划分成n个子集合，然后在每个数据集上使用不同的算法，则得到n个模型，再通过取平均值，取多数票等方法，即可得到bagging的结果。对于boosting算法，在一轮预测之后，提高错误分类样本的权重，使分类器着重在下一轮预测时处理这些样本。

Q45:如果你有一个数据集，其中，p（变量或特征的数量）大于n（数据集的大小）。为什么普通的最小二乘法不能工作，应该选择什么算法，为什么

在如此高维的数据集中，我们不能使用经典的回归方法，因为他们的假设会不成立。当p大于n时，不能使用最小二乘来进行系数估计，因为方差会趋于无限大，这时我们应使用正则化技术，如lasso，LARS，ridge等可以收缩系数来减小方差。精确地说，应该使用ridge回归方法来处理这种最小二乘具有高方差的情况。

Q46:我们知道one-hot编码会大大提高数据集的维度，但是标签编码不会，为什么

这是因为one-hot编码针对每一个类别变量都增加了一个变量。

Q47:买了这件商品的人，也买了这些。。推荐系统用了什么算法

协同过滤（collaborative filtering）

协同过滤算法在推荐商品的时候考虑用户行为。通过利用其他用户的商品交易历史，打分，选择和支付信息，这些行为和偏好被用于为新用户推荐商品。

Q48:如何理解第一类错误和第二类错误

第一类：假正，即本来是负类，分类器将其归为正类

第二类：假负，即本来是正类，分类器将其归为负类

Q49:你在处理一个分类问题，为了验证目的，你随机采样了训练集并将其分成了训练集和验证集。你在验证集上得到了较好的效果，但是在测试集上效果很差。为什么

在分类任务中，我们必须使用分层抽样而不是随机抽样，因为分层抽样并没有考虑目标类别的在新数据集的比例。而分层抽样可以维持目标类别在新数据集中的分布。

Q50:在kmeans或knn算法中，我们使用欧氏距离而不是曼哈顿距离，为什么

因为曼哈顿距离只能计算要么水平，要么竖直的距离，因此有维度限制。而欧式距离可以应用在任何空间，任何维度。

Q51:我们知道线性回归使用$R^{2}$或F值评价方法。但你如何评价一个逻辑回归模型

- 因为逻辑回归是用来预测概率的，因此我们可以使用AUC-ROC曲线及confusion matrix来评估其性能
- 同时，类比$R^{2}$在逻辑回归中的指标是AIC。AIC是用来选择模型系数的个数的。
- Null偏差表示一个模型预测的响应，只有一个截距。降低其值，得到更好的模型。剩余偏差表示模型在添加自变量时预测的响应。降低其值，得到更好的模型。

Q52:给定一个数据集，如何选择合适的机器学习算法

你应该说，如何选择算法完全取决于数据类型。如果你的数据集表现出线性，那么线性回归是最合适的。如果你的数据是图像，音频等，那么神经网络更合适。

如果数据包括非线性相互作用，那么应选择boosting或bagging算法。如果业务要求是构建可以部署的模型，那么我们将使用回归或决策树模型（易于解释），而不是黑盒算法，如svm，GBM等。

Q53:你如何理解偏差方差权衡

数学上可以将源于任何模型的误差分为三部分：

$$
Err(x) = (E[\hat{f}(x)]-f(x))^{2}+E[\hat{f}(x)-E[\hat{f}(x)]]^{2}+\sigma_{e}^{2}\\
Err(x)=Bias^{2}+Variance+Irreducible Error
$$

偏差对于量化与实际值不同的预测值的平均值有用。高偏差意味着我们的模型欠拟合，另一方面方差量化了对同一观察结果的预测的偏离度。高方差模型意味着过拟合，对于unseen数据表现不佳。

Q54:普通最小二乘法之于线性回归，正如最大似然之于逻辑回归，阐述其内涵

简言之，ols和ml都是用来估计未知参数（系数）的回归方法。ols用在线性回归中，以获得使真实和预测值距离最短的近似估计参数。最大似然用来选择能使所选参数最大概率产生观测数据的参数。














