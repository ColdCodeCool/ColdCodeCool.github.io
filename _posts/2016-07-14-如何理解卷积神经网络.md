---
layout: post
title: "Understand Convolutional Neural Network"
data: 2016-07-14 09:38:08
categories: posts
---
## 动机
卷积神经网络(Convolutional Neural Network)是由生物启发的, 对MLP的变种. 从Hubel和Wiesel的早期对猫的视觉皮层的实验来看, 我们知道这些视觉皮层包含一种复杂排列的细胞. 这些细胞对视觉皮层的一小部分区域敏感, 成为感受域或感受场. 这些子区域拼贴形成了整个视觉皮层. 这些细胞对输入空间表现地像一个本地滤波器, 并且非常善于利用自然图像中的本地空间强关联.

另外, 两种基本的细胞类型被证实: 在感受域内对边缘特征反应最强的简单细胞. 拥有更大感受域的复杂细胞, 并且对特定位置特征反应基本不变.

动物的视觉皮层是已知的最强大的视觉处理系统, 所以我们的研究很自然地开始模拟这种系统.

## 稀疏连接
卷积神经网络通过在相邻网络层之间使用一种本地连接类型来利用动物视觉皮层的空间本地相关性特点, 如下图:

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/sparse.png)

假想m-1层是输入视网膜层, 在上图中m层的单元在输入视网膜层的感知域宽度为3, 并且仅与3个相邻的神经元相连. m+1层的单元与低一层的网络的连接与以上情况类似, 但我们说该层与输入层的感知域宽度为5.每个单元对其在视网膜层的感知域之外的变化是无反应的, 这种架构就保证了学习到的"滤波器"对空间上的本地输入模型产生最大的响应.

但是, 随着这些网络层的增加会导致(非线性)"滤波器"会增长性地"全局化"(即对越来越大的像素空间产生响应), 举例来说m+1层的单元可以编码一个宽度为5的非线性特征.

## 权值共享
在卷积神经网络中, 每个滤波器$h_i$在整个视觉域上被复制. 这些被复制的单元共享相同的权值和偏置, 并且构成了一个特征图(feature map).

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/feature.png)

在上图中, 我们看到3个隐藏单元同属一个feature map. 相同颜色的权值是相等的, 梯度下降仍然可以用来学习这些共享的参数, 只需要对原算法做出微小改动.一个共享权值的梯度是所有共享参数的梯度之和.

复制的单元以这种方式使得特征可以被提取而不管他们在视觉域中的位置. 另外, 权值共享也可以使得学习效率大大提升.

## Details and Notation
一个feature map可以通过重复在整个图像的子区域里使用一个函数来获得, 换句话说, 通过在输入图像中与一个线性滤波器进行卷积, 加一个偏置项并且应用一个非线性函数. 如果我们将某个给定网络层的第k个feature map用$h^k$来表示, 滤波器由权值$W^k$和偏置$b_k$决定, 那么$h^k$可以通过以下公式得到:

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/hk.png)

为了更丰富地表征数据, 每一个隐含层由多个feature maps组成,$\{ h^{(k)},k=0..K \}$.