---
layout: post
title: "Understand Convolutional Neural Network"
data: 2016-07-14 09:38:08
categories: posts
---
## 动机
卷积神经网络(Convolutional Neural Network)是由生物启发的, 对MLP的变种. 从Hubel和Wiesel的早期对猫的视觉皮层的实验来看, 我们知道这些视觉皮层包含一种复杂排列的细胞. 这些细胞对视觉皮层的一小部分区域敏感, 成为感受域或感受场. 这些子区域拼贴形成了整个视觉皮层. 这些细胞对输入空间表现地像一个本地滤波器, 并且非常善于利用自然图像中的本地空间强关联.

另外, 两种基本的细胞类型被证实: 在感受域内对边缘特征反应最强的简单细胞. 拥有更大感受域的复杂细胞, 并且对特定位置特征反应基本不变.

动物的视觉皮层是已知的最强大的视觉处理系统, 所以我们的研究很自然地开始模拟这种系统.

## 稀疏连接
卷积神经网络通过在相邻网络层之间使用一种本地连接类型来利用动物视觉皮层的空间本地相关性特点, 如下图:

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/sparse.png)

假想m-1层是输入视网膜层, 在上图中m层的单元在输入视网膜层的感知域宽度为3, 并且仅与3个相邻的神经元相连. m+1层的单元与低一层的网络的连接与以上情况类似, 但我们说该层与输入层的感知域宽度为5.每个单元对其在视网膜层的感知域之外的变化是无反应的, 这种架构就保证了学习到的"滤波器"对空间上的本地输入模型产生最大的响应.

但是, 随着这些网络层的增加会导致(非线性)"滤波器"会增长性地"全局化"(即对越来越大的像素空间产生响应), 举例来说m+1层的单元可以编码一个宽度为5的非线性特征.

## 权值共享
在卷积神经网络中, 每个滤波器$h_i$在整个视觉域上被复制. 这些被复制的单元共享相同的权值和偏置, 并且构成了一个特征图(feature map).

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/feature.png)

在上图中, 我们看到3个隐藏单元同属一个feature map. 相同颜色的权值是相等的, 梯度下降仍然可以用来学习这些共享的参数, 只需要对原算法做出微小改动.一个共享权值的梯度是所有共享参数的梯度之和.

复制的单元以这种方式使得特征可以被提取而不管他们在视觉域中的位置. 另外, 权值共享也可以使得学习效率大大提升.

## Details and Notation
一个feature map可以通过重复在整个图像的子区域里使用一个函数来获得, 换句话说, 通过在输入图像中与一个线性滤波器进行卷积, 加一个偏置项并且应用一个非线性函数. 如果我们将某个给定网络层的第k个feature map用$h^k$来表示, 滤波器由权值$W^k$和偏置$b_k$决定, 那么$h^k$可以通过以下公式得到:

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/hk.png)

为了更丰富地表征数据, 每一个隐含层由多个feature maps组成,$h^{(k)},k=0..K$. 一个隐含层的权值$W$可以表示成一个包含每个目标feature map, 源feature map, 源垂直位置, 源水平位置的4D tensor. 偏置$b$可以表示成包含每个目标feature map的元素的向量. 我们通过下图来解释:

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/convolutional_layer.png)

上图展示了一个卷积神经网络的两层, ,m-1层包含四个feature maps, m层包含两个feature maps($h^0$和$h^1$).$h^0$和$h^1$中的像素(分别用蓝色和红色标记出来的)由m-1层的落在同一2x2感知域(由颜色标记的)的像素计算得到. 注意到感知域是如何在输入feature maps中张成的, $h^0$和$h^1$的权值$W^0$与$W^1$是3D权值tensors. 最重要的维度是标记是哪一个输入feature map的维度, 其他两个维度代表像素坐标.

综合起来, $W_{ij}^{kl}$表示连接第m层第k个feature map的每个像素与第m-1层在第l个feature map (i, j)处像素的权值.

## 卷积算子
ConvOp是Theano中实现卷积层的主要驱动力.ConvOp包含在库`theano.tensor.signal.conv2d`中, 包含两个符号形输入:
- 一个4D tensor, 表示一个mini-batch的输入图像. tensor的形式:[mini-batch size, number of input feature maps, image height, image width]
- 一个4D tensor, 代表权值矩阵$W$.tensor的形式:[number of feature maps at layer m, number of feature maps at layer m-1, filter height, filter width]

下面是一段由Theano实现的卷积层代码, 输入由3个feature maps组成(RGB color image), size是120x160. 我们使用两个9x9的感知域形成的卷积滤波器:
{% highlight python %}
import theano
from theano import tensor as T
from theano.tensor.nnet import conv2d

import numpy

rng = numpy.random.RandomState(23455)

# instantiate 4D tensor for input
input = T.tensor4(name='input')

# initialize shared variable for weights.
w_shp = (2, 3, 9, 9)
w_bound = numpy.sqrt(3 * 9 * 9)
W = theano.shared( numpy.asarray(
            rng.uniform(
                low=-1.0 / w_bound,
                high=1.0 / w_bound,
                size=w_shp),
            dtype=input.dtype), name ='W')

# initialize shared variable for bias (1D tensor) with random values
# IMPORTANT: biases are usually initialized to zero. However in this
# particular application, we simply apply the convolutional layer to
# an image without learning the parameters. We therefore initialize
# them to random values to "simulate" learning.
b_shp = (2,)
b = theano.shared(numpy.asarray(
            rng.uniform(low=-.5, high=.5, size=b_shp),
            dtype=input.dtype), name ='b')

# build symbolic expression that computes the convolution of input with filters in w
conv_out = conv2d(input, W)

# build symbolic expression to add bias and apply activation function, i.e. produce neural net layer output
# A few words on ``dimshuffle`` :
#   ``dimshuffle`` is a powerful tool in reshaping a tensor;
#   what it allows you to do is to shuffle dimension around
#   but also to insert new ones along which the tensor will be
#   broadcastable;
#   dimshuffle('x', 2, 'x', 0, 1)
#   This will work on 3d tensors with no broadcastable
#   dimensions. The first dimension will be broadcastable,
#   then we will have the third dimension of the input tensor as
#   the second of the resulting tensor, etc. If the tensor has
#   shape (20, 30, 40), the resulting tensor will have dimensions
#   (1, 40, 1, 20, 30). (AxBxC tensor is mapped to 1xCx1xAxB tensor)
#   More examples:
#    dimshuffle('x') -> make a 0d (scalar) into a 1d vector
#    dimshuffle(0, 1) -> identity
#    dimshuffle(1, 0) -> inverts the first and second dimensions
#    dimshuffle('x', 0) -> make a row out of a 1d vector (N to 1xN)
#    dimshuffle(0, 'x') -> make a column out of a 1d vector (N to Nx1)
#    dimshuffle(2, 0, 1) -> AxBxC to CxAxB
#    dimshuffle(0, 'x', 1) -> AxB to Ax1xB
#    dimshuffle(1, 'x', 0) -> AxB to Bx1xA
output = T.nnet.sigmoid(conv_out + b.dimshuffle('x', 0, 'x', 'x'))

# create theano function to compute filtered images
f = theano.function([input], output)
{% endhighlight %}