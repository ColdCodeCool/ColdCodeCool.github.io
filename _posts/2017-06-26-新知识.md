---
layout: post
title: "PCA学习"
date: 2017-06-26 15:26:55
categories: posts
---
## 知识点
imshow should be followed by waitKey function which displays the image for specified milliseconds. Otherwise, it won’t display the image. For example, waitKey(0) will display the window infinitely until any keypress (it is suitable for image display). waitKey(25) will display a frame for 25 ms, after which display will be automatically closed. (If you put it in a loop to read videos, it will display the video frame-by-frame). Here's a working example:

{% highlight python %}
import cv2

img = cv2.imread('a.jpg')
cv2.imshow('FRAME', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
{% endhighlight %}


## 2017.06.29
编译tensorflow ios camera项目，遇到linking library错误，错误显示

-lprotobuf-lite not found

Google上并未有人遇到过，问题在于项目内两个红色的共享库，libprotobuf-lite.a，libprotobuf.a被加入了链接库路径，在链接库里删除这两个项目之后，编译通过。

## 问题：dyld: Library not loaded: bazel-out/local-py3-opt/bin/tensorflow/libtensorflow.so
  Referenced from: /Users/inflation/workspace/link_test/./a.out
  Reason: image not found

Seems like you're using OS X.
For that your choices are to either:

Copy libtensorflow.so into /usr/local/lib
Or use DYLD_LIBRARY_PATH (e.g., export DYLD_LIBRARY_PATH=/path/to/dir/containing/libtensorflow.so)
Hope that helps


## 2017.06.30
One thing to check is to see whether the checkpoint actually has a value for InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1. You can use inspect_checkpoint to do this.
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/inspect_checkpoint.py

You'd do something like this:

$ bazel build tensorflow/python/tools:inspect_checkpoint
$ bazel-bin/tensorflow/python/tools/inspect_checkpoint --file_name=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_findtune/model.ckpt-23293
That will dump out the tensors that are saved in the checkpoint. I'm suspecting your checkpoint will not contain InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1.

But that doesn't fix your problem. One thing you might try is rather than picking the first checkpoint that becomes available, pick the last one after things have run for a while. I don't actually expect this to help, but there's an off-chance that this might work.

Otherwise it's possible that you simply can't change the optimizer when fine-tuning.

Let me know how the above works out.

## 2017.7.1
可以训练一个YOLO模型再加HED，做image semantic segmantation

## 2017.7.4

## 2017.7.5
仍然没有解决deeplab的AddN操作在ios版本tensorflow中不支持的问题

## 2017.7.7
事实证明，在tensorflow ios版本中，如果有超过两个计算结点求和，即使加入中间变量使他们两两求和，最终的效果仍然是他们直接求和，出现AddN invalid argument问题。

## 2017.7.11
tf.cast可以把一个tensor变量转换成numpy 变量，从而可以方便数学操作

## 2017.7.12
1.针对Pascal voc human parts数据集，当裁剪图像尺寸较小时，标签的部分人物mask会丢失，由于对loss进行了处理，会使此时的loss较高，这时应选用较大尺寸，如512

2.将loss中的beta分子变为pos之后，loss下降

## 2017.7.14
遇到大bug，用cv2做resize和read，修改过后不能正确启动，改用skimage.io之后正常！

## 2017.7.17
卷积层的工作原理是，每一个卷积核的尺寸等于卷积核宽W乘以高H，再乘以上一层数据的通道数。

CNN最成功的应用是CV，那为什么NLP和Speech的很多问题也可以用CNN做出来？为什么AlphaGo里也用了CNN？这几个不相关问题的相似性在哪里？CNN通过什么手段抓住了这个共性？为什么很多做人脸的paper会最后加入一个local connected conv？

CNN能在这几个领域成功的原因是图片、语音和文本都有局部相似性。人脸最后加local connected的原因是因为不再conbolution了，因为人的眼睛不是满脸都有的。

## 2017.7.18
#### 1x1卷积核的作用？

1.控制通道（channel）个数，升维或降维

2.加入非线性，提升网络的表达能力

3.实现跨通道的交互和信息整合，实现多个feature map的线性组合

#### Relu的作用

1.省计算，如sigmoid等函数，反向传播求误差梯度时，求导涉及除法，计算量相对大

2.对于深层网络，sigmoid函数反向传播时，很容易就会出现梯度消失的情况（在sigmoid接近饱和区时，变换太缓慢，导数趋于0）

3.Relu会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生

#### Sigmoid激励的特点

优点：平滑函数，便于求导

缺点：容易出现梯度消失，函数输出并不是zero-centered，幂运算相对比较耗时

sigmoid导数的最大值是0.25，这意味着导数在每一层至少会被压缩为原来的1/4，在经过多层后会达到接近0，此外sigmoid函数的输出值恒大于0，这会导致模型训练的收敛速度变慢。

#### Relu
优点：解决了gradient vanishing问题（在正区间），导数为1；计算速度非常快，只需要判断输入是否大于0；收敛速度远快于sigmoid和tanh

注意点：1.ReLU的输出也不是zero-centered 2.Dead ReLU problem，是指某些神经元可能永远不会被激活，导致相应的参数永远不能	被更新。有两个主要原因可能导致这种情况的产生（1）非常不幸的参数初始化，（2）learning rate太高导致在训练过程中参数更新太大，不幸使网络进入这种状态。解决方法是使用Xavier初始化方法，以及避免learning rate设置太大或使用adagrad等自动调节learning rate的方法

#### Leaky ReLU
f（x）= max（0.01x，x），提出是为了解决Dead ReLU problem，即将前半段设置为非0.

### Batch Normalization

1. Reduce internal covariate shift
covariate shift是指对学习系统来说，输入数据分布的变化。在深度网络的语境下，每一层的输入是受所有输入层参数影响的。	所以即使一个小的变化，都会随着网络深度被放大。神经网络在输入白化并不相关的情况下收敛更快

2. Reduce the dependence of gradients on the scale of parameters or their initial value

3. Regularizes the model and reduces the need for dropout, photometric distortions, local response normalization and other regularization techniques

4. Allows use of saturating nonlinearities and higher learning rates

## 2017.7.19
#### Goodfellow书中对参数共享的解释
In the case of convolution, the particular form of parameter sharing causes thelayer to have a property calledequivarianceto translation. To say a function isequivariant means that if the input changes, the output changes in the same way

在卷积的情况下，参数共享的特定形式使得该层具有等价变换的属性。说一个函数是等价的意味着如果输入变化，则输出以相同的方式变化。

Specifically，a function $f(x)$ is equivariant to a function $g$ if $f(g(x))=g(f(x))$. In the case of convolution, if we let $g$ be any function that translates the input, i.e., shifts it, then the convolution function is equivariant to $g$. For example, let $I$ be a function giving image brightness at integer coordinates. Let $g$ be a function mapping one image function to another image function, such that $I'=g(I)$ is the image function with $I'(x,y) = I(x-1,y)$.

特别地，一个函数和另一个函数等价变换意味着它们互相映射的结果相同。在卷积的情况下，若g是将图像平移，$I'$是将图像映射为另一个图像。上式将图像$I$的每一个像素往右平移一个单位，如果我们将这个变换应用于$I$，然后再施加卷积操作，结果等效于先施加卷积操作于$I'$，然后再施加平移变换操作。

When processing time series data, this means that convolution produces a sort of timeline that shows when diﬀerent features appear in the input. If we move an event later in time in the input, the exact same representation of it will appear in the output, just later in time. Similarly with images, convolution creates a 2-D map of where certain features appear in the input. If we move the object in the input, its representation will move the same amount in the output.

当处理时间序列数据时，这意味着卷积在输入中出现不同特征时产生了一种时间轴。如果我们将输入中的事件延后，同样的表征也会延后出现在输出中。这种情况同样适用于图像，卷积生成了出现在输入中的特定特征的2D映射。如果我们在输入中移动物体，它的表征也会在输出中移动相同的量。

This is useful for when we know that some functionof a small number of neighboring pixels is useful when applied to multiple inputlocations. For example, when processing images, it is useful to detect edges inthe ﬁrst layer of a convolutional network. The same edges appear more or lesseverywhere in the image, so it is practical to share parameters across the entire image.

当我们知道少量相邻像素的某些功能应用在多个输入图像的位置上很有用时，这种参数共享机制是有好处的。举例来说，当处理图像时，在卷积网络的第一层检测图像边缘是有用的。相同的边缘或多或少地出现在图像的各个位置，所以在整个图像共享参数是实际的。

In some cases, we may not wish to share parameters across the entireimage. For example, if we are processing images that are cropped to be centeredon an individual’s face, we probably want to extract diﬀerent features at diﬀerentlocations—the part of the network processing the top of the face needs to look foreyebrows, while the part of the network processing the bottom of the face needs tolook for a chin.

但在某些情况下，我们可能不希望在整个图像上共享参数。例如，如果我们正在处理被裁减为个人脸部的图像时，我们可能希望在不同的地方提取不同的功能，网络处理顶部的部分需要看起来像眉毛，而另外的部分网络处理图片底部需要看起来像下巴。

Convolution is not naturally equivariant to some other transformations, suchas changes in the scale or rotation of an image. Other mechanisms are necessaryfor handling these kinds of transformations.

卷积并不等于一些其他变换，例如图像的尺度或旋转，其他机制的引入是处理这些变化所必需的。

Finally, some kinds of data cannot be processed by neural networks deﬁned bymatrix multiplication with a ﬁxed-shape matrix. Convolution enables processingof some of these kinds of data.

最后，某些类型的数据不能通过固定形状的矩阵乘法定义的神经网络来处理，而卷积操作可以处理这些类型的数据。

#### Pooling层作用
按分类，max pooling，average pooling，L2 norm pooling，weighted average pooling based on the distance from the central pixel. In all cases, pooling helps to make the representation become approximatelyinvariantto small translations of the input. Invariance to translation means thatif we translate the input by a small amount, the values of most of the pooledoutputs do not change.

所有的pooling操作都是帮助使这些表征对于小的输入变换呈现出近似不变性。变换不变形意味着如果我们稍微移动一下输入，经过池化之后的大多数输出都不会改变。

Invariance to local translation can be a very useful property if we care more about whether some feature is present than exactly where it is. For example, when determining whether an image contains a face, we need not know the location of the eyes with pixel-perfect accuracy, we just need to know that there is an eye on the left side of the face and an eye on the right side of the face. In other contexts, it is more important to preserve the location of a feature. For example, if we want to ﬁnd acorner deﬁned by two edges meeting at a speciﬁc orientation, we need to preservethe location of the edges well enough to test whether they meet.

如果我们更关心是否存在某些特征，那么局部变换的不变性可能是非常有用的属性。例如，当确定图像是否包含脸部时，我们不需要以完美的准确度知道眼睛的位置，我们只需要知道脸的左右边分别有一只眼睛。但在其他情景中，保留眼睛的位置更为重要。例如，如果我们想要找到一个以特定方向相交的两个边缘构成的角落，那么我们需要保证边缘的位置足够精确以测试它们是否相交。

The use of pooling can be viewed as adding an inﬁnitely strong prior that the function the layer learns must be invariant to small translations. When this assumption is correct, it can greatly improve the statistical eﬃciency of the network.

池化的使用可以被视作加入了无穷强的先验信息，即该层学习到的功能必须对小的变换保持不变性。当这种假设成立的时候，就可以极大地提升网络的统计效率。

Pooling over spatial regions produces invariance to translation, but if we pool over the outputs of separately parametrized convolutions, the features can learn which transformations to become invariant to.

在空间区域上进行池化产生了变换不变性，但是如果我们对不同参数化卷积得到的输出进行池化，这些特征就会学习到应该对哪些变换保持不变性。

## 2017.7.20
#### 似然函数与交叉熵
似然函数是解释以model的输出为参数的某分布模型对样本集的解释程度，而交叉熵是直接衡量两个分布，或者说两个model之间的差异。

作为损失函数的似然函数，接收的输入为predict，label。而在这里，label是似然函数的观测值，即该似然函数的样本集。而其对应的模型，则是predict这个随机变量所服从的概率分布模型。它的目的，就是衡量predict背后的模型对当前观测值的解释程度。对于多类别分类，loss即可由多项式分布的似然函数来表征：

$$
L = f_{multinomial}(label;predict)
$$

整个样本集或一个batch的似然函数即：

$$
L = \frac{1}{n}\sum_{X}(label;predict)=\frac{1}{n}\sum_{X}\prod_{i=1}^{C}predict(i)^{label(i)}
$$

取对数：

$$
L = \frac{1}{n}\sum_{X}\sum_{i=1}^{C}label(i)log(predict(i))
$$

而最大化对数似然函数等价于最小化负对数似然函数，即平时所见到的形式。

Cross-entropy：对于某种分布的随机变量X~p(x)，有一个模型q(x)用于近似p(x)的概率分布，则分布X与模型q之间的交叉熵为

$$
H(X,q) = -\sum_{x}p(x)\log q(x)
$$

这里的X的分布模型即样本集label的真实分布模型，这里模型q(x)即想要模拟真实分布模型的机器学习模型。因此，可以说交叉熵是直接衡量两个分布，或者说两个model之间的差异。而似然函数则是解释以model的输出为参数的某分布模型对样本集的解释程度。

## 2017.07.23
通过ssh远程登录服务器跑程序，可以利用screen工具，这样做的好处是即使ssh断开，程序也不会中断运行

## 2017.07.26
此次训练参数设置为12，24，48，96，192，输出层没有收敛到一个理想值

## 2017.08.07
训练数据去除明暗、对比度增强之后，loss下降很多，说明在该任务中明暗和对比度增强不必要

## 2017.08.08
batch size改成8之后loss增大
