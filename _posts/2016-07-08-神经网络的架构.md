---
layout: post
title: "神经网络的架构"
data: 2016-07-08 15:12:19
categories: Deeplearning
---
## Architecture
假设我们有下面的一个网络:

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/archi.png)

我们把第一层叫`input layer`(输入层), 中间那一层叫`hidden layer`, 最后一层叫`output layer`. input layer和output layer都相当容易理解, 但hidden layer听起来可能有些神秘, 当我第一次看到这个词时, 甚至觉得带有某种深刻的哲学或数学意义. 但事实上, 它仅仅就是"不是输入层也不是输出层的网络层". 上图当中仅有一个隐藏层, 事实上其他网络可能有多个隐藏层. 由于历史的原因, 上图的多层网络有时被叫做 multilayer perceptrons或MLPs, 而忽略了它们是由sigmoid neurons构成的事实. 

输入和输出层往往是直观的, 例如, 我们要判断一个手写体的图片是否是数字"9". 一个自然的联想是将图片的像素密度编码为输入神经元的输入, 若图片是一张64 x 64的灰度图, 那么我们有4096=64 x 64个输入神经元, 像素密度在0到1之间. 输出层只有一个神经元, 当输出大于0.5时, 输入图像是"9", 否则不是"9".

虽然输入和输出层的设计是简单直观的, 但是隐藏层的设计相当有技巧. 隐藏层神经元的个数选择直接影响到计算量的大小, 但是好在研究者们开发出许多如何设计隐藏层的技巧. 直到现在, 我们都在讨论神经元的输出作为下一层神经元输入的网络, 我们称这种网络为前馈网络, feedforward neural network. 即网络中没有循环, 但其他类型的网络如recurrent neural network当中是存在这些循环的.

## A simple network to classify handwritten digits
我们使用一个三层网络:

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/three.png)

上图网络的输入层由一张28 x 28个像素的图片编码构成, 每个像素的灰度值由0到1, 0代表白色, 1代表黑色. 隐藏层由15个神经元构成, 输出层由10个神经元构成, 如果第一个神经元被激发, 即输出约为1, 那么我们将这个图片识别为0.

你也许会思考这样一个问题, 为什么我们要使用10个神经元作为输出层. 毕竟, 这个网络的目标是告诉我们哪个数字代表了输入的图像. 一个看起来自然的方式是我们只需要4个二元输出神经元就可以表征所有10个数字, 因为4个神经元可以表示16种结果. 那么为什么我们还需要使用10个神经元. 事实上, 这个问题可以由实验证明, 我们同时使用两种方式来设计网络, 结果是使用10个输出神经元的效果要比4个更好. 

为了理解这个现象, 我们考虑使用10个神经元的结构. 我们考虑第一个输出神经元, 它根据隐藏层的加权输出来判断输入图片是否为"0". 那么隐藏层神经元是干嘛的? 好吧, 我们假设隐藏层的第一个神经元负责检测一张图片是否出现下面图片的部分:

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/part.png)

那么, 隐藏层第一个神经元要做的事情就是赋予与上图位置重叠的像素极高的权重, 而对输入的其他像素位置赋予很小的权值. 类似地, 我们假设第二, 三, 四个隐藏层神经元是要检测如下图位置的像素是否存在:

![image](https://github.com/ColdCodeCool/ColdCodeCool.github.io/raw/master/images/hidden.png)

正如你猜地那样, 这四个图像组合起来就是数字"0". 所以, 如果上面四个隐藏层神经元都被激发, 那么我们可以总结出输入的图像就是数字"0". 当然, 上面的四个证据组合并不唯一指向数字"0". 我们可以合法地得到更多其他的数字"0"的图像组合. 但是, 在此例子中, 我总结得到输入为数字"0"显然是安全的.

如果这就是神经网络的工作模式, 那么我们可以给出为什么10个输出神经元比4个要更好的解释. 假设我们只有4个输出神经元, 那么第一个输出神经元将要尝试决定输入图像的哪一个bit最重要, 这对于仅有4个输出神经元的网络是十分困难的.

## Learning with gradient descent

